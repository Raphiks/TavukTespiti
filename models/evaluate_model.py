import os
import glob
from PIL import Image
from torchvision.transforms import functional as F
import torch

def evaluate_model(model, test_img_dir, device, threshold=0.5):
    print(f"ğŸ“ Test klasÃ¶rÃ¼: {test_img_dir}")
    
    # jpg, jpeg, png uzantÄ±larÄ±nÄ± al
    img_paths = sorted(glob.glob(os.path.join(test_img_dir, "*.jpg")) +
                       glob.glob(os.path.join(test_img_dir, "*.jpeg")) +
                       glob.glob(os.path.join(test_img_dir, "*.png")))

    print(f"ğŸ” Bulunan gÃ¶rsel sayÄ±sÄ±: {len(img_paths)}")
    if len(img_paths) == 0:
        print("ğŸš« Test klasÃ¶rÃ¼nde uygun gÃ¶rsel bulunamadÄ±.")
        return

    model.eval()
    total = len(img_paths)
    detected = 0

    for idx, path in enumerate(img_paths):
        print(f"[{idx+1}/{total}] GÃ¶rsel iÅŸleniyor: {os.path.basename(path)}")

        image = Image.open(path).convert("RGB")
        img_tensor = F.to_tensor(image).unsqueeze(0).to(device)

        with torch.no_grad():
            outputs = model(img_tensor)

        scores = outputs[0]['scores'].cpu().numpy()
        print(f"  ğŸ”¸ Tahmin edilen kutu sayÄ±sÄ±: {len(scores)}")
        print(f"  ğŸ”¸ Skorlar: {scores}")

        if any(score > threshold for score in scores):
            detected += 1
            print("  âœ… En az bir tespit var (eÅŸik Ã¼stÃ¼)")
        else:
            print("  âŒ Tespit yok veya skorlar dÃ¼ÅŸÃ¼k")

    print("\n" + "=" * 50)
    print(f"ğŸ“Š Toplam GÃ¶rsel SayÄ±sÄ±: {total}")
    print(f"ğŸ¯ Tespit YapÄ±lan GÃ¶rsel SayÄ±sÄ±: {detected}")
    print(f"ğŸ“ˆ Tespit OranÄ±: %{(detected / total * 100):.2f}")
    print("=" * 50)
